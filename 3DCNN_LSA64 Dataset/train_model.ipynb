{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb331dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, ZeroPadding3D, BatchNormalization\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling3D, Conv3D, MaxPooling2D\n",
    "from collections import deque\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2dc53e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResearchModels():\n",
    "    \n",
    "    def __init__(self, nb_classes, model, seq_length,\n",
    "                     saved_model=None, features_length=2048):\n",
    "\n",
    "        self.seq_length = seq_length\n",
    "        self.load_model = load_model\n",
    "        self.saved_model = saved_model\n",
    "        self.nb_classes = nb_classes\n",
    "        self.feature_queue = deque()\n",
    "\n",
    "        metrics = ['accuracy']\n",
    "        if self.nb_classes >= 10:\n",
    "            metrics.append('top_k_categorical_accuracy')\n",
    "\n",
    "        if self.saved_model is not None:\n",
    "            print(\"Loading model %s\" % self.saved_model)\n",
    "            self.model = load_model(self.saved_model)\n",
    "        elif model == 'lstm':\n",
    "            print(\"Loading LSTM model.\")\n",
    "            self.input_shape = (seq_length, features_length)\n",
    "            self.model = self.lstm()\n",
    "        elif model == 'lrcn':\n",
    "            print(\"Loading CNN-LSTM model.\")\n",
    "            self.input_shape = (seq_length, 80, 80, 3)\n",
    "            self.model = self.lrcn()\n",
    "        elif model == 'mlp':\n",
    "            print(\"Loading simple MLP.\")\n",
    "            self.input_shape = (seq_length, features_length)\n",
    "            self.model = self.mlp()\n",
    "        elif model == 'conv_3d':\n",
    "            print(\"Loading Conv3D\")\n",
    "            self.input_shape = (seq_length, 80, 80, 3)\n",
    "            self.model = self.conv_3d()\n",
    "        elif model == 'c3d':\n",
    "            print(\"Loading C3D\")\n",
    "            self.input_shape = (seq_length, 80, 80, 3)\n",
    "            self.model = self.c3d()\n",
    "        else:\n",
    "            print(\"Unknown network.\")\n",
    "            sys.exit()\n",
    "\n",
    "        # Now compile the network.\n",
    "        optimizer = Adam(lr=1e-5, decay=1e-6)\n",
    "        self.model.compile(loss='categorical_crossentropy', optimizer=optimizer,\n",
    "                           metrics=metrics)\n",
    "\n",
    "        print(self.model.summary())\n",
    "        \n",
    "    def lstm(self):\n",
    "        # Model.\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(2048, return_sequences=False,\n",
    "                       input_shape=self.input_shape,\n",
    "                       dropout=0.2))\n",
    "        model.add(Dense(512, activation='relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(self.nb_classes, activation='softmax'))\n",
    "\n",
    "        return model\n",
    "      \n",
    "    def lrcn(self):\n",
    "        model = Sequential()\n",
    "        model.add(TimeDistributed(Conv2D(32, (7, 7), strides=(2, 2), activation='relu', padding='same'), input_shape=self.input_shape))\n",
    "        model.add(TimeDistributed(Conv2D(32, (3,3), kernel_initializer=\"he_normal\", activation='relu')))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "        model.add(TimeDistributed(Conv2D(64, (3,3), padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(Conv2D(64, (3,3), padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "        model.add(TimeDistributed(Conv2D(128, (3,3), padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(Conv2D(128, (3,3), padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "        model.add(TimeDistributed(Conv2D(256, (3,3), padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(Conv2D(256, (3,3), padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))        \n",
    "        model.add(TimeDistributed(Conv2D(512, (3,3), padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(Conv2D(512, (3,3), padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "        model.add(TimeDistributed(Flatten()))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(LSTM(256, return_sequences=False, dropout=0.5))\n",
    "        model.add(Dense(self.nb_classes, activation='softmax'))\n",
    "\n",
    "        return model\n",
    "    \n",
    "    def conv_3d(self):\n",
    "        model = Sequential()\n",
    "        model.add(Conv3D(32, kernel_size=(3, 3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=self.input_shape))\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "        model.add(BatchNormalization(center=True, scale=True))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Conv3D(64, kernel_size=(3, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "        model.add(BatchNormalization(center=True, scale=True))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(256, activation='relu', kernel_initializer='he_uniform'))\n",
    "        model.add(Dense(256, activation='relu', kernel_initializer='he_uniform'))\n",
    "        model.add(Dense(self.nb_classes, activation='softmax'))\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48b710b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger\n",
    "from data import DataSet\n",
    "import time\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "263f7443",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data_type, seq_length, model, saved_model=None, class_limit=None, image_shape=None, load_to_memory=False, batch_size=32, \n",
    "          nb_epoch=100):\n",
    "    \n",
    "    # Helper: Save the model.\n",
    "    checkpointer = ModelCheckpoint(\n",
    "        filepath=os.path.join('data', 'checkpoints', model + '-' + data_type + '.{epoch:03d}-{val_loss:.3f}.hdf5'),\n",
    "        verbose=1,\n",
    "        save_best_only=True)\n",
    "\n",
    "    # Helper: TensorBoard\n",
    "    tb = TensorBoard(log_dir=os.path.join('data', 'logs', model))\n",
    "\n",
    "    # Helper: Stop when we stop learning.\n",
    "    early_stopper = EarlyStopping(patience=5)\n",
    "\n",
    "    # Helper: Save results.\n",
    "    timestamp = time.time()\n",
    "    csv_logger = CSVLogger(os.path.join('data', 'logs', model + '-' + 'training-' + str(timestamp) + '.log'))\n",
    "\n",
    "    # Get the data and process it.\n",
    "    if image_shape is None:\n",
    "        data = DataSet(\n",
    "            seq_length=seq_length,\n",
    "            class_limit=class_limit\n",
    "        )\n",
    "    else:\n",
    "        data = DataSet(\n",
    "            seq_length=seq_length,\n",
    "            class_limit=class_limit,\n",
    "            image_shape=image_shape\n",
    "        )\n",
    "\n",
    "    # Get samples per epoch.\n",
    "    # Multiply by 0.7 to attempt to guess how much of data.data is the train set.\n",
    "    steps_per_epoch = (len(data.data) * 0.7) // batch_size\n",
    "\n",
    "    if load_to_memory:\n",
    "        # Get data.\n",
    "        X, y = data.get_all_sequences_in_memory('train_videos', data_type)\n",
    "        X_test, y_test = data.get_all_sequences_in_memory('test_videos', data_type)\n",
    "    else:\n",
    "        # Get generators.\n",
    "        generator = data.frame_generator(batch_size, 'train_videos', data_type)\n",
    "        val_generator = data.frame_generator(batch_size, 'test_videos', data_type)\n",
    "\n",
    "    # Get the model.\n",
    "    rm = ResearchModels(len(data.classes), model, seq_length, saved_model)\n",
    "\n",
    "    # Fit!\n",
    "    if load_to_memory:\n",
    "        # Use standard fit.\n",
    "        rm.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=batch_size,\n",
    "            validation_data=(X_test, y_test),\n",
    "            verbose=1,\n",
    "            callbacks=[tb, early_stopper, csv_logger],\n",
    "            epochs=nb_epoch)\n",
    "    else:\n",
    "        # Use fit generator.\n",
    "        rm.model.fit_generator(\n",
    "            generator=generator,\n",
    "            steps_per_epoch=steps_per_epoch,\n",
    "            epochs=nb_epoch,\n",
    "            verbose=1,\n",
    "            callbacks=[tb, early_stopper, csv_logger, checkpointer],\n",
    "            validation_data=val_generator,\n",
    "            validation_steps=40,\n",
    "            workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "488ab400",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"These are the main training settings. Set each before running\n",
    "    this file.\"\"\"\n",
    "    # model can be one of lstm, lrcn, mlp, conv_3d, c3d\n",
    "    model = 'conv_3d'\n",
    "    saved_model = None  # None or weights file\n",
    "    class_limit = None  # int, can be 1-101 or None\n",
    "    seq_length = 40\n",
    "    load_to_memory = False  # pre-load the sequences into memory\n",
    "    batch_size = 1\n",
    "    nb_epoch = 10\n",
    "    image_shape = None\n",
    "\n",
    "    # Chose images or features and image shape based on network.\n",
    "    if model in ['conv_3d', 'c3d', 'lrcn']:\n",
    "        data_type = 'images'\n",
    "        image_shape = (80, 80, 3)\n",
    "    elif model in ['lstm', 'mlp']:\n",
    "        data_type = 'features'\n",
    "        image_shape = None\n",
    "    else:\n",
    "        raise ValueError(\"Invalid model. See train.py for options.\")\n",
    "        \n",
    "    train(data_type, seq_length, model, saved_model=saved_model,\n",
    "          class_limit=class_limit, image_shape=image_shape,\n",
    "          load_to_memory=load_to_memory, batch_size=batch_size, nb_epoch=nb_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0f46df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Conv3D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\LEGION\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d (Conv3D)              (None, 38, 78, 78, 32)    2624      \n",
      "_________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D) (None, 19, 39, 39, 32)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 19, 39, 39, 32)    128       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 19, 39, 39, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 17, 37, 37, 64)    55360     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 8, 18, 18, 64)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 8, 18, 18, 64)     256       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 8, 18, 18, 64)     0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 165888)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               42467584  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 24)                6168      \n",
      "=================================================================\n",
      "Total params: 42,597,912\n",
      "Trainable params: 42,597,720\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "None\n",
      "Creating train_videos generator with 240 samples.\n",
      "Epoch 1/10\n",
      "1007/1007 [==============================] - ETA: 0s - loss: 1.9251 - accuracy: 0.4796 - top_k_categorical_accuracy: 0.7527Creating test_videos generator with 240 samples.\n",
      "1007/1007 [==============================] - 1133s 1s/step - loss: 1.9251 - accuracy: 0.4796 - top_k_categorical_accuracy: 0.7527 - val_loss: 1.2072 - val_accuracy: 0.6500 - val_top_k_categorical_accuracy: 0.9000\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.20724, saving model to data\\checkpoints\\conv_3d-images.001-1.207.hdf5\n",
      "Epoch 2/10\n",
      "1007/1007 [==============================] - 1104s 1s/step - loss: 0.4029 - accuracy: 0.8798 - top_k_categorical_accuracy: 0.9861 - val_loss: 1.1497 - val_accuracy: 0.6750 - val_top_k_categorical_accuracy: 0.9250\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.20724 to 1.14972, saving model to data\\checkpoints\\conv_3d-images.002-1.150.hdf5\n",
      "Epoch 3/10\n",
      "1007/1007 [==============================] - 7093s 7s/step - loss: 0.1079 - accuracy: 0.9682 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4109 - val_accuracy: 0.9000 - val_top_k_categorical_accuracy: 1.0000\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.14972 to 0.41094, saving model to data\\checkpoints\\conv_3d-images.003-0.411.hdf5\n",
      "Epoch 4/10\n",
      "1007/1007 [==============================] - 1056s 1s/step - loss: 0.0488 - accuracy: 0.9871 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.2305 - val_accuracy: 0.9250 - val_top_k_categorical_accuracy: 1.0000\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.41094 to 0.23054, saving model to data\\checkpoints\\conv_3d-images.004-0.231.hdf5\n",
      "Epoch 5/10\n",
      "1007/1007 [==============================] - 1143s 1s/step - loss: 0.0542 - accuracy: 0.9930 - top_k_categorical_accuracy: 0.9990 - val_loss: 0.4078 - val_accuracy: 0.8250 - val_top_k_categorical_accuracy: 1.0000\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.23054\n",
      "Epoch 6/10\n",
      "1007/1007 [==============================] - 1089s 1s/step - loss: 0.1404 - accuracy: 0.9623 - top_k_categorical_accuracy: 0.9980 - val_loss: 0.6325 - val_accuracy: 0.8250 - val_top_k_categorical_accuracy: 0.9250\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.23054\n",
      "Epoch 7/10\n",
      "1007/1007 [==============================] - 1116s 1s/step - loss: 0.0209 - accuracy: 0.9950 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.1554 - val_accuracy: 0.9500 - val_top_k_categorical_accuracy: 1.0000\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.23054 to 0.15541, saving model to data\\checkpoints\\conv_3d-images.007-0.155.hdf5\n",
      "Epoch 8/10\n",
      "1007/1007 [==============================] - 1138s 1s/step - loss: 0.0033 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.3810 - val_accuracy: 0.9000 - val_top_k_categorical_accuracy: 0.9750\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.15541\n",
      "Epoch 9/10\n",
      "1007/1007 [==============================] - 1141s 1s/step - loss: 0.0214 - accuracy: 0.9950 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4507 - val_accuracy: 0.8250 - val_top_k_categorical_accuracy: 1.0000\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.15541\n",
      "Epoch 10/10\n",
      "1007/1007 [==============================] - 1148s 1s/step - loss: 9.0712e-04 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.1966 - val_accuracy: 0.9250 - val_top_k_categorical_accuracy: 1.0000\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.15541\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
